{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2f530f",
   "metadata": {},
   "source": [
    "# Detailed Results Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee426e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Ensure images directory exists\n",
    "images_dir = 'mystery-em-dash/analysis_results_substack/images/'\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "# Read JSON files from analysis_results_substack folder\n",
    "with open('mystery-em-dash/analysis_results_substack/paraphrase_results_20250704_022337.json', 'r') as f:\n",
    "    paraphrase_data = json.load(f)\n",
    "\n",
    "with open('mystery-em-dash/analysis_results_substack/story_analyses_20250704_000807.json', 'r') as f:\n",
    "    story_data = json.load(f)\n",
    "\n",
    "# Create complete_analysis_results structure for compatibility with existing functions\n",
    "complete_analysis_results = {\n",
    "    'paraphrase_results': paraphrase_data,\n",
    "    'story_analysis': story_data\n",
    "}\n",
    "\n",
    "# Also create the analysis_data variable that some functions expect\n",
    "analysis_data = complete_analysis_results\n",
    "\n",
    "print(\"\u2705 Loaded and structured analysis data:\")\n",
    "print(f\"Paraphrase results type: {type(paraphrase_data)}\")\n",
    "print(f\"Story analysis type: {type(story_data)}\")\n",
    "print(f\"Paraphrase results length: {len(paraphrase_data) if isinstance(paraphrase_data, list) else 'N/A (not a list)'}\")\n",
    "print(f\"Story analysis length: {len(story_data) if isinstance(story_data, list) else 'N/A (not a list)'}\")\n",
    "print(f\"Complete analysis results keys: {list(complete_analysis_results.keys())}\")\n",
    "print(\"\\n\ud83d\udcca Data ready for analysis functions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_token_distribution_graphs(complete_analysis_results):\n",
    "    \"\"\"\n",
    "    Create token distribution graphs showing token changes when paraphrasing em dash sentences.\n",
    "    Uses custom color scheme: background #fef6f0, text #5b4230, bars #f77854\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from collections import defaultdict, Counter\n",
    "    \n",
    "    # Extract token differences by model from the analysis results\n",
    "    model_changes = defaultdict(list)\n",
    "    \n",
    "    if 'paraphrase_results' in complete_analysis_results:\n",
    "        for result in complete_analysis_results['paraphrase_results']:\n",
    "            model = result.get('model', 'unknown')\n",
    "            token_diff = result.get('token_difference', 0)\n",
    "            model_changes[model].append(token_diff)\n",
    "    \n",
    "    # Custom color scheme\n",
    "    background_color = '#fef6f0'\n",
    "    text_color = '#5b4230'\n",
    "    bar_color = '#f77854'\n",
    "    \n",
    "    # Set global matplotlib parameters\n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': background_color,\n",
    "        'axes.facecolor': background_color,\n",
    "        'text.color': text_color,\n",
    "        'axes.labelcolor': text_color,\n",
    "        'xtick.color': text_color,\n",
    "        'ytick.color': text_color,\n",
    "        'axes.edgecolor': text_color,\n",
    "        'grid.color': text_color,\n",
    "        'grid.alpha': 0.3\n",
    "    })\n",
    "    \n",
    "    # Create figure with three subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.patch.set_facecolor(background_color)\n",
    "    fig.suptitle('Token Change Distributions by Model\\\\n(Paraphrasing Sentences with Em Dashes)', \n",
    "                 fontsize=16, fontweight='bold', color=text_color, y=1.02)\n",
    "    \n",
    "    # Define model order\n",
    "    models = ['gpt-4', 'gpt-4.1', 'gpt-35-turbo']\n",
    "    \n",
    "    # Create plots for each model\n",
    "    for i, model in enumerate(models):\n",
    "        ax = axes[i]\n",
    "        ax.set_facecolor(background_color)\n",
    "        \n",
    "        if model in model_changes and len(model_changes[model]) > 0:\n",
    "            changes = model_changes[model]\n",
    "            \n",
    "            # Count frequencies\n",
    "            counter = Counter(changes)\n",
    "            values = sorted(counter.keys())\n",
    "            frequencies = [counter[v] for v in values]\n",
    "            \n",
    "            # Create the bar plot\n",
    "            bars = ax.bar(values, frequencies, color=bar_color, alpha=0.8, \n",
    "                         edgecolor=text_color, linewidth=0.8)\n",
    "            \n",
    "            # Add statistics\n",
    "            mean_change = np.mean(changes)\n",
    "            std_change = np.std(changes)\n",
    "            total_count = len(changes)\n",
    "            \n",
    "            # Create display name for graph titles (rename gpt-4 to gpt-4o)\n",
    "            display_model = model.replace('gpt-4', 'gpt-4o') if model == 'gpt-4' else model\n",
    "            \n",
    "            # Customize the plot\n",
    "            ax.set_title(f'{display_model.upper()}\\\\n({total_count} paraphrases)', \n",
    "                        fontsize=14, fontweight='bold', color=text_color, pad=20)\n",
    "            ax.set_xlabel('Token Change (- = Decrease, + = Increase)', \n",
    "                         fontsize=12, color=text_color)\n",
    "            ax.set_ylabel('Frequency', fontsize=12, color=text_color)\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add statistics text box\n",
    "            stats_text = f'Mean: {mean_change:.3f}\\\\nStd: {std_change:.3f}'\n",
    "            bbox_props = dict(boxstyle='round,pad=0.5', facecolor='white', \n",
    "                            edgecolor=text_color, alpha=0.9)\n",
    "            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "                    verticalalignment='top', bbox=bbox_props,\n",
    "                    fontsize=11, color=text_color)\n",
    "            \n",
    "            # Set x-axis to show all integer values in range\n",
    "            if values:\n",
    "                min_val, max_val = min(values), max(values)\n",
    "                ax.set_xlim(min_val - 0.5, max_val + 0.5)\n",
    "                ax.set_xticks(range(min_val, max_val + 1))\n",
    "            \n",
    "            # Highlight the zero line (no change)\n",
    "            ax.axvline(x=0, color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "            \n",
    "            # Add percentage calculations\n",
    "            increases = sum(1 for x in changes if x > 0)\n",
    "            decreases = sum(1 for x in changes if x < 0) \n",
    "            no_change = sum(1 for x in changes if x == 0)\n",
    "            \n",
    "            print(f\"\ud83d\udcca {display_model.upper()} TOKEN DISTRIBUTION:\")\n",
    "            print(f\"   \u2022 Total paraphrases: {total_count}\")\n",
    "            print(f\"   \u2022 Mean change: {mean_change:.3f} tokens\")\n",
    "            print(f\"   \u2022 Standard deviation: {std_change:.3f}\")\n",
    "            print(f\"   \u2022 Increases: {increases} ({increases/total_count*100:.1f}%)\")\n",
    "            print(f\"   \u2022 Decreases: {decreases} ({decreases/total_count*100:.1f}%)\")\n",
    "            print(f\"   \u2022 No change: {no_change} ({no_change/total_count*100:.1f}%)\")\n",
    "            print(f\"   \u2022 Range: {min_val} to {max_val} tokens\")\n",
    "            print()\n",
    "        else:\n",
    "            # Create display name for no data case too\n",
    "            display_model = model.replace('gpt-4', 'gpt-4o') if model == 'gpt-4' else model\n",
    "            ax.text(0.5, 0.5, f'No data available\\\\nfor {display_model.upper()}', \n",
    "                   transform=ax.transAxes, ha='center', va='center',\n",
    "                   fontsize=12, color=text_color)\n",
    "            ax.set_title(f'{display_model.upper()}\\\\n(No data)', \n",
    "                        fontsize=14, fontweight='bold', color=text_color)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plots to images folder\n",
    "    images_dir = 'mystery-em-dash/analysis_results_substack/images/'\n",
    "    plt.savefig(f'{images_dir}token_distribution_by_model.png', dpi=300, bbox_inches='tight', \n",
    "                facecolor=background_color, edgecolor='none')\n",
    "    plt.savefig(f'{images_dir}token_distribution_by_model.pdf', bbox_inches='tight', \n",
    "                facecolor=background_color, edgecolor='none')\n",
    "    \n",
    "    print(\"\ud83d\udcca GRAPHS GENERATED:\")\n",
    "    print(f\"   \u2022 {images_dir}token_distribution_by_model.png\")\n",
    "    print(f\"   \u2022 {images_dir}token_distribution_by_model.pdf\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Reset matplotlib parameters to default\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "# Create token distribution graphs if analysis data is available\n",
    "if 'analysis_data' in globals() and analysis_data is not None:\n",
    "    print(\"\ud83c\udfa8 CREATING TOKEN DISTRIBUTION GRAPHS WITH CUSTOM COLORS...\")\n",
    "    print(\"\ud83c\udfa8 Color scheme: Background #fef6f0, Text #5b4230, Bars #f77854\")\n",
    "    print()\n",
    "    create_token_distribution_graphs(analysis_data)\n",
    "else:\n",
    "    print(\"\u274c No analysis results found. Token distribution graphs require paraphrase results with token differences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6954947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_token_distribution_graphs(complete_analysis_results):\n",
    "    \"\"\"\n",
    "    Create separate graph files for each model showing token changes.\n",
    "    Uses custom color scheme: background #fef6f0, text #5b4230, bars #f77854\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from collections import defaultdict, Counter\n",
    "    \n",
    "    # Extract token differences by model from the analysis results\n",
    "    model_changes = defaultdict(list)\n",
    "    \n",
    "    if 'paraphrase_results' in complete_analysis_results:\n",
    "        for result in complete_analysis_results['paraphrase_results']:\n",
    "            model = result.get('model', 'unknown')\n",
    "            token_diff = result.get('token_difference', 0)\n",
    "            model_changes[model].append(token_diff)\n",
    "    \n",
    "    # Custom color scheme\n",
    "    background_color = '#fef6f0'\n",
    "    text_color = '#5b4230'\n",
    "    bar_color = '#f77854'\n",
    "    \n",
    "    # Set global matplotlib parameters\n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': background_color,\n",
    "        'axes.facecolor': background_color,\n",
    "        'text.color': text_color,\n",
    "        'axes.labelcolor': text_color,\n",
    "        'xtick.color': text_color,\n",
    "        'ytick.color': text_color,\n",
    "        'axes.edgecolor': text_color,\n",
    "        'grid.color': text_color,\n",
    "        'grid.alpha': 0.3\n",
    "    })\n",
    "    \n",
    "    # Define model order\n",
    "    models = ['gpt-4', 'gpt-4.1', 'gpt-35-turbo']\n",
    "    saved_files = []\n",
    "    \n",
    "    # Create individual plots for each model\n",
    "    for model in models:\n",
    "        if model in model_changes and len(model_changes[model]) > 0:\n",
    "            changes = model_changes[model]\n",
    "            \n",
    "            # Create a single figure for this model\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "            fig.patch.set_facecolor(background_color)\n",
    "            ax.set_facecolor(background_color)\n",
    "            \n",
    "            # Count frequencies\n",
    "            counter = Counter(changes)\n",
    "            values = sorted(counter.keys())\n",
    "            frequencies = [counter[v] for v in values]\n",
    "            \n",
    "            # Create the bar plot\n",
    "            bars = ax.bar(values, frequencies, color=bar_color, alpha=0.8, \n",
    "                         edgecolor=text_color, linewidth=0.8)\n",
    "            \n",
    "            # Add statistics\n",
    "            mean_change = np.mean(changes)\n",
    "            std_change = np.std(changes)\n",
    "            total_count = len(changes)\n",
    "            \n",
    "            # Create display name for graph titles (rename gpt-4 to gpt-4o)\n",
    "            display_model = model.replace('gpt-4', 'gpt-4o') if model == 'gpt-4' else model\n",
    "            \n",
    "            # Customize the plot\n",
    "            ax.set_title(f'{display_model.upper()} Token Distribution\\\\n({total_count} paraphrases)', \n",
    "                        fontsize=16, fontweight='bold', color=text_color, pad=20)\n",
    "            ax.set_xlabel('Token Change (- = Decrease, + = Increase)', \n",
    "                         fontsize=12, color=text_color)\n",
    "            ax.set_ylabel('Frequency', fontsize=12, color=text_color)\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add statistics text box\n",
    "            stats_text = f'Mean: {mean_change:.3f}\\\\nStd: {std_change:.3f}'\n",
    "            bbox_props = dict(boxstyle='round,pad=0.5', facecolor='white', \n",
    "                            edgecolor=text_color, alpha=0.9)\n",
    "            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "                    verticalalignment='top', bbox=bbox_props,\n",
    "                    fontsize=11, color=text_color)\n",
    "            \n",
    "            # Set x-axis to show all integer values in range\n",
    "            if values:\n",
    "                min_val, max_val = min(values), max(values)\n",
    "                ax.set_xlim(min_val - 0.5, max_val + 0.5)\n",
    "                ax.set_xticks(range(min_val, max_val + 1))\n",
    "            \n",
    "            # Highlight the zero line (no change)\n",
    "            ax.axvline(x=0, color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "            \n",
    "            # Adjust layout\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save individual files for this model to images folder\n",
    "            images_dir = 'mystery-em-dash/analysis_results_substack/images/'\n",
    "            model_clean = model.replace('-', '_')  # For filename compatibility\n",
    "            png_filename = f'{images_dir}token_distribution_{model_clean}.png'\n",
    "            pdf_filename = f'{images_dir}token_distribution_{model_clean}.pdf'\n",
    "            \n",
    "            plt.savefig(png_filename, dpi=300, bbox_inches='tight', \n",
    "                        facecolor=background_color, edgecolor='none')\n",
    "            plt.savefig(pdf_filename, bbox_inches='tight', \n",
    "                        facecolor=background_color, edgecolor='none')\n",
    "            \n",
    "            saved_files.extend([png_filename, pdf_filename])\n",
    "            \n",
    "            # Show the plot\n",
    "            plt.show()\n",
    "            \n",
    "            # Close the figure to free memory\n",
    "            plt.close(fig)\n",
    "            \n",
    "            print(f\"\ud83d\udcca {display_model.upper()} individual graphs saved:\")\n",
    "            print(f\"   \u2022 {png_filename}\")\n",
    "            print(f\"   \u2022 {pdf_filename}\")\n",
    "            print()\n",
    "        else:\n",
    "            # Create display name for no data case too\n",
    "            display_model = model.replace('gpt-4', 'gpt-4o') if model == 'gpt-4' else model\n",
    "            print(f\"\u274c No data available for {display_model.upper()}\")\n",
    "    \n",
    "    # Reset matplotlib parameters to default\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    \n",
    "    print(f\"\u2705 Created {len(saved_files)} individual graph files\")\n",
    "    return saved_files\n",
    "\n",
    "# Create individual graph files for each model\n",
    "if 'analysis_data' in globals() and analysis_data is not None:\n",
    "    print(\"\ud83c\udfa8 CREATING INDIVIDUAL GRAPH FILES FOR EACH MODEL...\")\n",
    "    print(\"\ud83c\udfa8 Color scheme: Background #fef6f0, Text #5b4230, Bars #f77854\")\n",
    "    print()\n",
    "    individual_files = create_individual_token_distribution_graphs(analysis_data)\n",
    "    \n",
    "    print(\"\ud83d\udcc1 ALL INDIVIDUAL FILES CREATED:\")\n",
    "    for file in individual_files:\n",
    "        print(f\"   \u2022 {file}\")\n",
    "else:\n",
    "    print(\"\u274c No analysis results found. Please run the complete analysis first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcc1 VERIFY ALL GRAPH FILES WERE CREATED\n",
    "import os\n",
    "\n",
    "print(\"\ud83d\udcca TOKEN DISTRIBUTION GRAPH FILES SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combined graphs (all models in one image)\n",
    "combined_files = [\n",
    "    'token_distribution_by_model.png',\n",
    "    'token_distribution_by_model.pdf'\n",
    "]\n",
    "\n",
    "# Individual graphs (one per model)\n",
    "individual_files = [\n",
    "    'token_distribution_gpt_4.png',\n",
    "    'token_distribution_gpt_4.pdf',\n",
    "    'token_distribution_gpt_4.1.png', \n",
    "    'token_distribution_gpt_4.1.pdf',\n",
    "    'token_distribution_gpt_35_turbo.png',\n",
    "    'token_distribution_gpt_35_turbo.pdf'\n",
    "]\n",
    "\n",
    "print(\"\ud83d\udd17 COMBINED GRAPHS (all models together):\")\n",
    "for file in combined_files:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file)\n",
    "        print(f\"   \u2705 {file} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"   \u274c {file} (missing)\")\n",
    "\n",
    "print(f\"\\\\n\ud83d\udcca INDIVIDUAL GRAPHS (separate file per model):\")\n",
    "for file in individual_files:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file)\n",
    "        print(f\"   \u2705 {file} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"   \u274c {file} (missing)\")\n",
    "\n",
    "total_files = len([f for f in combined_files + individual_files if os.path.exists(f)])\n",
    "print(f\"\\\\n\ud83c\udfaf SUMMARY:\")\n",
    "print(f\"   \u2022 Total graph files created: {total_files}\")\n",
    "print(f\"   \u2022 Combined graph files: {len([f for f in combined_files if os.path.exists(f)])}\")\n",
    "print(f\"   \u2022 Individual graph files: {len([f for f in individual_files if os.path.exists(f)])}\")\n",
    "print(f\"   \u2022 File formats: PNG (high-res) and PDF (vector)\")\n",
    "print(f\"   \u2022 Color scheme: Custom warm palette (#fef6f0, #5b4230, #f77854)\")\n",
    "\n",
    "print(f\"\\\\n\u2705 All graphs saved successfully!\")\n",
    "print(f\"\ud83d\udca1 Use individual files when you need to focus on one model\")\n",
    "print(f\"\ud83d\udca1 Use combined file when comparing all models side-by-side\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiexpress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}